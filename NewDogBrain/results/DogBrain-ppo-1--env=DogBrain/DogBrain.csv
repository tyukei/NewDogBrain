Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
3000,1.4189385,152.6,0.23107047,1.0359523139501874,1.0359523139501874,1.0
6000,1.4189386,200.2,0.19614439,1.1957204262415568,1.1957204262415568,1.0
9000,1.4189385,170.94117647058823,0.20943478,1.0591046704965479,1.0591046704965479,1.0
12000,1.4189385,149.85,0.2083452,1.2020169124007225,1.2020169124007225,1.0
15000,1.4189386,198.46666666666667,0.21926145,1.2408105870087942,1.2408105870087942,1.0
18000,1.4189386,176.11764705882354,0.19813715,1.4122132027850431,1.4122132027850431,1.0
21000,1.418983,203.78947368421052,0.25039378,0.9716371307770412,0.9716371307770412,1.0
24000,1.4190423,181.66666666666666,0.29189187,0.8821928696706891,0.8821928696706891,1.0
27000,1.4190426,161.05555555555554,0.2794305,1.4861864944299061,1.4861864944299061,1.0
30000,1.4190423,224.28571428571428,0.260444,1.6069860862834113,1.6069860862834113,1.0
33000,1.4190425,184.75,0.2874952,1.1119397208094597,1.1119397208094597,1.0
36000,1.4190423,178.1875,0.2837026,1.3041049763560295,1.3041049763560295,1.0
39000,1.4190426,199.2,0.26894426,1.1856829543908438,1.1856829543908438,1.0
